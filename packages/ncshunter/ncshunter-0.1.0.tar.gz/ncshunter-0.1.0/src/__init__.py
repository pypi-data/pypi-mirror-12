# ------------------------------------
# python modules
# ------------------------------------

import os
import sys
import pandas
import numpy
from ngslib import Bed,IO,BedList,DB,Utils,GeneBed
import copy
from bisect import bisect_right,bisect_left
import motility
import pickle

# ------------------------------------
# constants
# ------------------------------------

TIS_site = set('ATG')
non_canonical_TIS_sites = set('ATG')

# translation tables
tables={}
tables["standard"]={
    'TTT': 'F', 'TTC': 'F', 'TTA': 'L', 'TTG': 'L', 'TCT': 'S',
    'TCC': 'S', 'TCA': 'S', 'TCG': 'S', 'TAT': 'Y', 'TAC': 'Y',
    'TGT': 'C', 'TGC': 'C', 'TGG': 'W', 'CTT': 'L', 'CTC': 'L',
    'CTA': 'L', 'CTG': 'L', 'CCT': 'P', 'CCC': 'P', 'CCA': 'P',
    'CCG': 'P', 'CAT': 'H', 'CAC': 'H', 'CAA': 'Q', 'CAG': 'Q',
    'CGT': 'R', 'CGC': 'R', 'CGA': 'R', 'CGG': 'R', 'ATT': 'I',
    'ATC': 'I', 'ATA': 'I', 'ATG': 'M', 'ACT': 'T', 'ACC': 'T',
    'ACA': 'T', 'ACG': 'T', 'AAT': 'N', 'AAC': 'N', 'AAA': 'K',
    'AAG': 'K', 'AGT': 'S', 'AGC': 'S', 'AGA': 'R', 'AGG': 'R',
    'GTT': 'V', 'GTC': 'V', 'GTA': 'V', 'GTG': 'V', 'GCT': 'A',
    'GCC': 'A', 'GCA': 'A', 'GCG': 'A', 'GAT': 'D', 'GAC': 'D',
    'GAA': 'E', 'GAG': 'E', 'GGT': 'G', 'GGC': 'G', 'GGA': 'G',
    'GGG': 'G', 'TAA': '@', 'TAG': '@', 'TGA': '@'}
# non-canonial 1st: NTG as start codon. Here to simplify the calculation, non-canonical start codons are set to lowercase 'm'
tables['non_canonical_TIS_lev1'] = copy.deepcopy(tables['standard'])
tables['non_canonical_TIS_lev1']['CTG'] = 'm'
tables['non_canonical_TIS_lev1']['TTG'] = 'm'
tables['non_canonical_TIS_lev1']['GTG'] = 'm'


# ------------------------------------
# Misc functions
# ------------------------------------

def gversion(gv='hg19'):
    if gv == 'mm10':
        genome = "/scratch/bcb/ywang52/TData/genomes/mm10/mm10.fa"
        ganno = "/scratch/bcb/ywang52/TData/genomes/mm10/gencode.vM4.annotation.gpd.gz"
        knownjuncfile = "/scratch/bcb/ywang52/TData/genomes/mm10/known_noncanonical_junctions.bed"
        gtffile = "/scratch/bcb/ywang52/TData/genomes/mm10/gencode.vM4.annotation.gtf.gz"
        return genome,ganno,knownjuncfile,gtffile
    elif gv == 'hg19':
        genome = "/scratch/bcb/ywang52/TData/genomes/hg19/gencode19/GRCh37.p13.genome.fa"
        ganno = "/scratch/bcb/ywang52/TData/genomes/hg19/gencode19/gencode.v19.chr_patch_hapl_scaff.annotation.gpd"           
        knownjuncfile = "/scratch/bcb/ywang52/TData/genomes/hg19/gencode19/known_noncanonical_junctions.bed"
        gtffile = "/scratch/bcb/ywang52/TData/genomes/hg19/gencode19/gencode.v19.chr_patch_hapl_scaff.annotation.gtf.gz"
        return genome,ganno,knownjuncfile,gtffile
    else:
        sys.exit("ERROR: genome version is not recognized.")

# ------------------------------------
# Classes
# ------------------------------------

class Junction(Bed):
    ''' Read MapSplice junctions.txt '''
    canonical_sites = ('ATAC', 'GTAT', 'CTGC', 'GCAG', 'GTAG', 'CTAC')
    canonical_sites_dict = {site:1 for site in canonical_sites}
    def __init__(self,x, site_at= 15):
        '''
        Junction class for MapSplice output.
        Parameters:
            x: string or list
                junction string or split string
            ftype: string
                Input file format
            site_at: string
                The column index (1-based) for junction site.
        '''
        super(Junction,self).__init__(x)
        self.site  = x[14]
        self.stop -= 1
    def is_canonical(self):
        return Junction.canonical_sites_dict.has_key(self.site)
    def checkBam(self,bamdb):
        '''
        Check if reads cover this junction.
        Parameters:
            bamdb: DB object
            Opened Bam file
        Returns:
            depth: int
            Minimum depth of the junction region 
        '''
        # We may get more information here.
        # for read in bamdb.fetch(self,chrom,self.start,self.stop):
        depth = bamdb.pileup(self.chrom,self.start,self.stop)
        return int(min(depth))
                            
class Junctions(BedList):
    def __init__(self,x=[]):
        super(self.__class__,self).__init__(x)
        self.ftype = 'junction'
    def readfile(self,juncfile,minlen=10,maxlen=200):
        '''
        Read junctions.txt, and apply filters on it.
        Parameters:
            juncfile: string
                junctions.txt generated by MapSplice.
            minlen: int
                Minimum length of junction
            maxlen: int
                maximum length of junction            
        '''
        IO.converters['junction'] = Junction # add Junction coverter
        for junc in IO.BioReader(juncfile,ftype='junction'):
            if minlen<= len(junc) <= maxlen and not junc.is_canonical():                
                self.append(junc)                
    def findCommon(self,B):
        if not self.sorted:
            self.sort()
        if not B.sorted:
            B.sort()
        idxA = 0
        idxB = 0
         
        LA = len(self)
        LB = len(B)
        while (idxA<LA and idxB<LB):
            if self[idxA] == B[idxB]:
                yield self[idxA],B[idxB]
                idxA += 1
                idxB += 1                
            elif self[idxA] < B[idxB]:
                idxA += 1
            else:
                idxB += 1

class NonCanonicalSplicing(object):
    # Solution 1: make the junctions as dict, search against the whole transcriptome
    # Solution 2: the reverse
    @staticmethod
    def getKnownJunctions(ganno,genome,outfile):
        existed = {}
        with DB(genome,'fasta') as db, open(outfile,'w') as ofh:
            for gene in IO.BioReader(ganno,'genepred'):
                for intron in gene.introns():
                    l = len(intron)
                    up = intron.extend(0,-l+2) # fist two bases
                    dn = intron.extend(-l+2,0) # last two bases
                    seq = up.fetchDB(db)+dn.fetchDB(db)
                    seq = seq.seq.upper()
                    if not Junction.canonical_sites_dict.has_key(seq):
                        key = '{0}\t{1}\t{2}'.format(intron.chrom,intron.start,intron.stop)
                        if not existed.has_key(key):
                            print >>ofh, "{0}\t{1}".format(intron,seq)
                            existed[key] = 1

    @staticmethod
    def removeKnownJunctions(juncs,knownjuncfile):
        '''
        Remove known junctions in a given known junctions list.
        '''
        known_juncs = {}
        for junc in IO.BioReader(knownjuncfile,ftype='bed'):
            known_juncs["{0}\t{1}\t{2}".format(junc.chrom,junc.start,junc.stop)] = 1
        for junc in juncs:
            #junc.score += junc2.score # sum up coverage.
            if not known_juncs.has_key("{0}\t{1}\t{2}".format(junc.chrom,junc.start,junc.stop)):
                yield junc

    @staticmethod
    def annoJunctions(ganno,juncs):
        '''
        Annotate junction files by gene annoations. Only junctions in the CDS regions are considered.
        Parameters:
            ganno: string
                Gene annotation in genepred format.
            juncs: list or Junctions
                A list of Junction objects
        Returns:
            sgenes: dict
                A dict of geneid:SplicedGene object
        '''
        sgenes = {}
        IO.converters['splicedgene'] = SplicedGene
        with DB(ganno,'genepred') as gdb:
            for junc in juncs:
                for sgene in gdb.fetch(junc.chrom,junc.start,junc.stop,converter='splicedgene'):
                    match_type = []
                    # check 5' UTR
                    utr5 = sgene.getUTR5()
                    if utr5:
                        for exon in utr5.exons():
                            if junc.isOverlap(exon):
                                match_type.append('UTR5')
                                break
                    # check CDS
                    cds = sgene.getCDS()
                    if cds:
                        for exon in cds.exons():
                            if junc.isOverlap(exon):
                                match_type.append('CDS')
                                break
                    # check 3' UTR
                    utr3 = sgene.getUTR3()
                    if utr3:
                        for exon in utr3.exons():
                            if junc.isOverlap(exon):
                                match_type.append('UTR3')
                                break
                    if match_type:
                        sgenes.setdefault(sgene.id,sgene)
                        sgene = sgenes[sgene.id]
                        sgene.junctions.append(junc)
                        sgene.junctypes.append(":".join(match_type))
        return sgenes
    
    @staticmethod
    def AlternativeORF(gene,junc,db):
        '''
        Find if there is alternative ORF after deletion.
        '''
        
        # check if junctions overlapped with cds
        cds = gene.getCDS()
        if not cds:
            return gene, "NO CODING REGION"
        if junc.stop <= gene.txstart or junc.start >= gene.txstop:
            return gene, "IN UTR"

        # check the details of overlap
        starts = []
        stops = []
        TSS = False
        TIS = gene.txstart if gene.strand == "+" else gene.txstop -1 # TIS
        for exon in gene.exons():
            if exon.isOverlap(junc):
                del_start = max(exon.start,junc.start)
                del_stop  = min(exon.stop,junc.stop)
                if exon.start < del_start: # first fragment
                    starts.append(exon.start)
                    stops.append(del_start)
                if exon.stop > del_stop: # 2nd fragment
                    starts.append(del_stop)
                    stops.append(exon.stop)
            else:
                starts.append(exon.start)
                stops.append(exon.stop)
                
        # generate new transcript
        tr = copy.deepcopy(gene)
        tr.exoncount = len(starts)
        tr.exonstarts = sorted(starts)
        tr.exonstops = sorted(stops)
        tr.start = tr.exonstarts[0]
        tr.stop = tr.exonstops[-1]
        # check if TIS is still there. if TIS is missing, find new ATG
        TIS = gene.txstart if gene.strand == "+" else gene.txstop -1 
        if TIS <junc.start or TIS >= junc.stop: 
            seq = tr.fetchDB(db).seq
            start_at = seq.find('ATG')
            if start_at == -1:
                tr.txstart = tr.txstop = tr.stop
                return tr, "NO CDS"
            # reset TIS
            l = 0
            for exon in tr.exons():
                nl = l + len(exon)
                if l <= start_at < nl:
                    if tr.strand == "+":
                        tr.txstart = exon.start + start_at - l
                    else:
                        tr.txstop = exon.stop - start_at + l         

        # Find stop codon. Step 1: Set txstop to the end of the transcript
        if gene.strand == "+":
            tr.txstop = tr.stop
        else:
            tr.txstart = tr.start
        cds = tr.getCDS()
        if not cds:
            return tr, "NO CDS"
        cds_seq = cds.fetchDB(db)
        # Find stop codon. Step 2: Find '@'
        cds_seq = cds_seq.seq[:len(cds_seq)/3*3]
        aa = Utils.toProtein(cds_seq)
        stop_at = aa.find('@') + 1
        if stop_at: # calculate txstop
            aa = aa[:stop_at]
            l = 0
            stop_at = stop_at *3
            for exon in cds.exons():
                le = len(exon)
                if stop_at <= le+l:
                    if gene.strand == "+":
                        tr.txstop = stop_at - l + exon.start
                    else:
                        tr.txstart = le + l - stop_at + exon.start
                    break
                l += le
            return tr, aa
        else: # no stop codon
            return tr, "NO STOP CODON"
    
    @staticmethod    
    def read_pwm(pwmfile):
        fh = open(pwmfile)
        line = fh.next()
        count = int(line.split()[4].split('=')[1])
        for i in range(7):
            fh.next()
        matrix = []
        for line in fh:
            line = [round(float(i)*count) for i in line.split()]
            line.append(0.)
            matrix.append(line)
        fh.close()
        return matrix

    @staticmethod
    def IDConverter(gtffile):
        ids = {}
        for interval in IO.BioReader(gtffile):
            if interval[2] == 'exon':
                #tr = {key:value.strip('"') for words in interval[-1].split(';')[:-1] for key, value in words.split() }
                tr = {}
                if not ids.has_key(interval[-1].split('"')[3]):
                    for words in interval[-1].split(';')[:-1]:
                        key,value = words.split()
                        tr[key] = value.strip('"')
                    ids[tr["transcript_id"]] = tr
        return ids

class SplicedGene(GeneBed):
    '''
    Gene affected by non-canonical splicing.
    '''
    def __init__(self,x,description=None):
        super(self.__class__,self).__init__(x,description)
        self.junctions = BedList()
        self.junctypes = []
        self.TIS = True
    def applyJunction(self,junc):
        '''
        Apply a junction to the transcript.
        '''
        starts, stops = zip(*[(tbed.start,tbed.stop) for exon in self.exons() for tbed in exon-junc])
        sg = copy.deepcopy(self)
        sg.exonstarts,sg.exonstops = list(sorted(starts)),list(sorted(stops))
        sg.exoncount = len(sg.exonstarts)
        # reset txstart and txstop if it is spliced.
        if junc.start <= self.txstart < junc.stop:
            sg.txstart = self.start
            sg.TIS = False if self.strand == "+" else True
        if junc.start < self.txstop <= junc.stop:
            sg.txstop = self.stop
            sg.TIS = False if self.strand == "-" else True
        return sg
    def findORF2(self,db,non_canonical= 'standard', min_size=10):
        '''
        Find all possible ORFs in the given sequence.
        Parameters:
            seq: string
                sequence for ORF searching
            non_canonical: string, choices from 'standard', 'on_canonical_TIS_lev1', 'on_canonical_TIS_lev2'
                check different levels of non-canonial TIS. Default is 'standard'.
                standard: only allow ATG as start codon.
                level 1: allow NTG as start codon.
                level 2: allow no more than 1 mismatch of ATGas start codon.
            min_size: int
                mininum number of amino acids.
        Yields:
            All possible ORFs.            
        '''
        # Fetch sequence.
        seq = self.fetchDB(db).seq
        l = len(seq)
        utr5 = self.getUTR5()
        utr3 = self.getUTR3()
        cds = self.getCDS()
        cds_pos = [utr5.getcDNALength() if utr5 else 0, l - utr3.getcDNALength() if utr3 else l]
        cds_frame = cds_pos[0]%3+1 if cds else 0
        end_types = ['UTR5','CDS','UTR3']
        # translation table 
        table = tables[non_canonical]
        for frame in range(3):
            # Translation in frame
            AA = Utils.toProtein(seq[frame:],table)
            # Find starts < junc_stop and stops > junc_start (overlapped with junction)
            starts = [i for i, ltr in enumerate(AA) if ltr.upper() == 'M']
            stops  = [i for i, ltr in enumerate(AA) if ltr == '@']
            if len(stops) == 0 :
                continue
            for start in starts:
                # find the nearest stop site
                if start > stops[-1]:
                    continue
                stop = stops[bisect_left(stops,start)]
                if stop-start >= min_size:
                    if not cds:
                        start_pos = "NCRNA"
                        stop_pos  = "NCRNA"
                    else:
                        start_pos = end_types[bisect_left(cds_pos,start*3+frame)]
                        stop_pos  = end_types[bisect_left(cds_pos,stop*3+frame)]
                    yield "{0}\t{1}\t{2}\t{3}\t{4}\t{5}\t{6}".format(self.id,self.proteinid,frame+1, cds_frame, start_pos, stop_pos, AA[start:stop])
    def findChange(self,db,junc):
        ''' Find how a junction affects the current CDS. '''
        # No CDS
        if self.txstart == self.txstop:
            return ""
        # transcript
        cdna = self.fetchDB(db).seq
        lcdna = len(cdna)
        utr5 = self.getUTR5()
        utr3 = self.getUTR3()
        cds  = self.getCDS()
        cds_start = utr5.getcDNALength() if utr5 else 0
        cds_stop  = cds_start + cds.getcDNALength()
        lcds = cds_stop - cds_start
        table = tables['standard']
        template = "{gid}\t{tid}\t"+self.strand+"\t{cdslength}\t{junc}\t{juncstart}\t{juncstop}\t{junctype}\t{details}"
        # parse junction to transcript coordinates
        junc_start,junc_start_status = self.transcript_position(max(junc.start,self.start))
        junc_stop, junc_stop_status  = self.transcript_position(min(junc.stop ,self.stop))
        if junc_start == junc_stop: # in intron
            return ""
        if junc_start > junc_stop:
            junc_start, junc_stop = junc_stop, junc_start
        ## test positions
        #lstr1 = cdna[:junc_start]+cdna[junc_stop:]
        #lstr2 = self.applyJunction(junc).fetchDB(db).seq
        #min_l = min(len(lstr1),len(lstr2))
        #min_i = 0
        #for i in range(min_l):
        #    if lstr1[i] != lstr2[i]:
        #        #min_i = i
        #        #break
        #if min_i == min_l-1:
        #    print self.id,junc.id,len(lstr1),len(lstr2),min_i,lstr1[min_i:min_i+10],lstr2[min_i:min_i+10]
        ## test postions ends
        # check if overlap with CDS
        if junc_stop<=cds_start or junc_start >=cds_stop:
            return ""
        # if cover TIS
        junc_str = "{0}:{1}-{2}:{3}\t{4}".format(junc.chrom,junc.start,junc.stop,junc.id,junc.score)
        if junc_start<= cds_start <junc_stop:
            return template.format(gid=self.proteinid,tid=self.id,cdslength="{0}:{1}".format(lcds,lcds/3-1),junc=junc_str,juncstart="{0}:{1}".format(junc_start-cds_start,junc_start_status),juncstop="{0}:{1}".format(junc_stop-cds_start,junc_stop_status),junctype="Transcription_start_site_missing",details="")
        # CDS 
        altCDS = cdna[cds_start:junc_start] + cdna[junc_stop:]
        altCDS = altCDS[:len(altCDS)/3*3]
        altORF = Utils.toProtein(altCDS,table)
        idx = altORF.find('@')
        ### test ORF
        #ORF = Utils.toProtein(cdna[cds_start:cds_stop])
        #min_l = min(len(ORF),len(altORF[:idx]))
        #min_i = min_l
        #for i in range(min_l):
        #    if ORF[i] != altORF[i]:
        #        #min_i = i
        #        #break
        #print "cDNA1:",cdna[cds_start:cds_stop]
        #print "cDNA2:",self.getCDS().fetchDB(db).seq
        #print "cDNA3:",altCDS
        #print ORF
        #print altORF[:idx]
        #print junc
        #print self.id,junc.id,self.strand,len(ORF),len(altORF),min_i*3,ORF[min_i-5:min_i+5],altORF[min_i-5:min_i+5]
        ## test ORF ends
        frame_shift = (junc_stop-junc_start)%3
        if idx == -1:
            junc_type = "Losing_stop_codon"
            details   = "No_alternative_stop_codon"
        else:
            if frame_shift == 0 and junc_stop<=cds_stop-3:
                junc_type = "Frame_shift_{0}".format(frame_shift)
                details = "In_frame_deletion,length:{0}:{1}".format(idx*3,idx)
            else:
                junc_type = "Frame_shift_{0}".format(frame_shift)
                details = "Alternative_stop_codon,length:{0}:{1}".format(idx*3,idx)
        return template.format(gid=self.proteinid,tid=self.id,cdslength="{0}:{1}".format(lcds,lcds/3-1),junc=junc_str,juncstart="{0}:{1}".format(junc_start-cds_start,junc_start_status),juncstop="{0}:{1}".format(junc_stop-cds_start,junc_stop_status),junctype=junc_type,details=details)
    def findORF(self,db,force=False): # not working currently due to difficulty in determination of TIS.
        if force or not self.TIS:
            lengths = [0]
            for exon in self.exons():
                lengths.append(len(exon) + lengths[-1])   
            seq = self.fetchDB(db).seq
            start_at = seq.find('ATG',0)              
            while(start_at != -1):
                subseq = seq[start_at:]
                idx = bisect_left(lengths,start_at) - 1
                sexon = self.getExon(idx+1)
                if self.strand == "+":
                    self.txstart = exon.start + start_at - lengths[idx]
                else:
                    self.txstop  = exon.stop  - start_at + lengths[idx]                
                aa = Utils.toProtein(subseq[:len(subseq)/3*3])
                stop_at = aa.find('@')
                if stop_at != -1:
                    aa = aa[:stop_at]
                    stop_at = start_at + stop_at*3                    
                    idx = bisect_left(lengths,stop_at) -1
                    exon = self.getExon(idx+1)
                    if self.strand == '+':
                        self.txstop = exon.start + stop_at - lengths[idx]
                    else:
                        self.txstart = exon.stop - stop_at + lengths[idx]
                    yield self,aa
                start_at = seq.find('ATG',start_at+1)
    def findStopCodon(self,db):
        if self.TIS:
            # set stop codon to the end of transcript
            if self.strand == "+":
                self.txstop = self.stop
            else:
                self.txstart = self.start
            cds = self.getCDS()
            if not cds:
                return self,"NO CDS"
            # exon accumulating lengths
            lengths = [0]
            for exon in cds.exons():
                lengths.append(len(exon) + lengths[-1])
            # translation
            cdsseq = cds.fetchDB(db).seq
            l = len(cdsseq)
            cdsseq = cdsseq[:len(cdsseq)/3*3]
            aa = Utils.toProtein(cdsseq)
            # find stop codon
            stop_at = aa.find('@') + 1
            if not stop_at:
                return self, "NO STOP CODON"
            # find stop postion
            aa = aa[:stop_at]
            stop_at *= 3
            idx = bisect_left(lengths,stop_at) - 1
            exon = cds.getExon(idx + 1)
            if self.strand == '+':
                self.txstop = exon.start + stop_at - lengths[idx]
            else:
                self.txstart = exon.stop - stop_at + lengths[idx]
            return self,aa

# ------------------------------------
# Main
# ------------------------------------

